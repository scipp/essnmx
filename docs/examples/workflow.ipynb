{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "## Collect Parameters and Providers\n",
    "### Simulation(McStas) Data\n",
    "There is a dedicated loader, ``load_mcstas_nexus`` for ``McStas`` simulation data workflow. <br>\n",
    "``MaximumProbability`` can be manually provided to the loader <br>\n",
    "to derive more realistic number of events. <br>\n",
    "It is because ``weights`` are given as probability, not number of events in a McStas file. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect parameters and providers\n",
    "import scipp as sc\n",
    "from ess.nmx.mcstas_loader import load_mcstas_nexus\n",
    "from ess.nmx.mcstas_loader import (\n",
    "    InputFilepath,\n",
    "    MaximumProbability,\n",
    "    DefaultMaximumProbability,\n",
    "    McStasEventWeightsConverter,\n",
    "    event_weights_from_probability,\n",
    "    McStasProtonChargeConverter,\n",
    "    proton_charge_from_event_data,\n",
    ")\n",
    "from ess.nmx.data import small_mcstas_sample\n",
    "from ess.nmx.reduction import bin_time_of_arrival, TimeBinSteps\n",
    "\n",
    "providers = (load_mcstas_nexus, bin_time_of_arrival, )\n",
    "\n",
    "file_path = small_mcstas_sample()  # Replace it with your data file path\n",
    "params = {\n",
    "    TimeBinSteps: TimeBinSteps(50),\n",
    "    InputFilepath: InputFilepath(file_path),\n",
    "    # Additional parameters for McStas data handling.\n",
    "    MaximumProbability: DefaultMaximumProbability,\n",
    "    McStasEventWeightsConverter: event_weights_from_probability,\n",
    "    McStasProtonChargeConverter: proton_charge_from_event_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``event weights converter`` and ``proton_charge_from_event_data`` are\n",
    "\n",
    "set as parameters for reproducibility of workflow and accessibility to the documentation.\n",
    "\n",
    "The reason of having them as parameters not as providers is,\n",
    "\n",
    "1. They are not part of general reduction, which are only for McStas cases.\n",
    "2. They are better done while the file is open and read in the loader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import get_type_hints\n",
    "param_reprs = {key.__name__: value for key, value in params.items()}\n",
    "prov_reprs = {\n",
    "    get_type_hints(prov)['return'].__name__: prov.__name__ for prov in providers\n",
    "}\n",
    "\n",
    "# Providers and parameters to be used for pipeline\n",
    "sc.DataGroup(**prov_reprs, **param_reprs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sciline as sl\n",
    "from ess.nmx.mcstas_loader import NMXData\n",
    "from ess.nmx.reduction import NMXReducedData\n",
    "\n",
    "nmx_pl = sl.Pipeline(list(providers), params=params)\n",
    "nmx_workflow = nmx_pl.get(NMXReducedData)\n",
    "nmx_workflow.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Desired Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event data grouped by detector panel and pixel id.\n",
    "dg = nmx_workflow.compute(NMXData)\n",
    "dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binned data.\n",
    "\n",
    "binned_dg = nmx_workflow.compute(NMXReducedData)\n",
    "binned_dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "``NMXReducedData`` object has a method to export the data into nexus or h5 file.\n",
    "\n",
    "You can save the result as ``test.nxs`` for example.\n",
    "\n",
    "```python\n",
    "binned_dg.export_as_nexus('test.nxs')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument View\n",
    "\n",
    "Pixel positions are not used for later steps,\n",
    "but it is included in the coordinates for instrument view.\n",
    "\n",
    "All pixel positions are relative to the sample position,\n",
    "therefore the sample is at (0, 0, 0).\n",
    "\n",
    "**It might be very slow or not work in the ``VS Code`` jupyter notebook editor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scippneutron as scn\n",
    "\n",
    "da = dg['weights']\n",
    "da.coords['position'] = dg['position']\n",
    "# Plot one out of 100 pixels to reduce size of docs output\n",
    "view = scn.instrument_view(da['id', ::100].hist(), pixel_size=0.0075)\n",
    "view.children[0].toolbar.cameraz()\n",
    "view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
