{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "In this example, we will use McStas 3 simulation file.\n",
    "\n",
    "## Build Pipeline (Collect Parameters and Providers)\n",
    "Import the providers from ``load_mcstas_nexus`` to use the ``McStas`` simulation data workflow. <br>\n",
    "``MaximumProbability`` can be manually provided to derive more realistic number of events. <br>\n",
    "It is because ``weights`` are given as probability, not number of events in a McStas file. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.nmx.mcstas import McStasWorkflow\n",
    "from ess.nmx.data import small_mcstas_3_sample\n",
    "\n",
    "from ess.nmx.types import *\n",
    "from ess.nmx.reduction import NMXReducedData, merge_panels\n",
    "from ess.nmx.nexus import export_as_nexus\n",
    "\n",
    "base_wf = McStasWorkflow()  # Instantiate the base workflow\n",
    "base_wf[FilePath] = small_mcstas_3_sample()  # Replace with the path to your own file\n",
    "base_wf[MaximumProbability] = 10_000\n",
    "base_wf[TimeBinSteps] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Types and Providers of the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_wf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph of the Workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_wf.visualize(NMXReducedData, graph_attr={\"rankdir\": \"LR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector Index Mapping\n",
    "\n",
    "We want to reduce all three panels, so we map the relevant part of the workflow over a list of the three panels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DetectorIndex selects what detector panels to include in the run\n",
    "# in this case we select all three panels.\n",
    "detector_panel_ids = {DetectorIndex: sc.arange('panel', 3, unit=None)}\n",
    "pipeline = base_wf.map(detector_panel_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Mapped Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sciline as sl\n",
    "\n",
    "pipeline.visualize(\n",
    "    sl.get_mapped_node_names(pipeline, NMXReducedData),\n",
    "    graph_attr={\"rankdir\": \"LR\"},\n",
    "    compact=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Mapped Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType\n",
    "\n",
    "MergedNMXReducedData = NewType('MergedNMXReducedData', sc.DataGroup)\n",
    "graph = pipeline.reduce(func=merge_panels, name=MergedNMXReducedData)\n",
    "graph.get(MergedNMXReducedData).visualize(compact=True, graph_attr={\"rankdir\": \"LR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Desired Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_dg = graph.compute(MergedNMXReducedData)\n",
    "binned_dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "``NMXReducedData`` object has a method to export the data into nexus or h5 file.\n",
    "\n",
    "You can save the result as ``test.nxs``, for example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_as_nexus(binned_dg, \"test.nxs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Intermediate Mapped Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.nmx.reduction import NMXData\n",
    "\n",
    "dg = merge_panels(\n",
    "    *pipeline.compute(sl.get_mapped_node_names(pipeline, NMXData)).values()\n",
    ")  # We need ``NMXData`` to use instrument view\n",
    "dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument View\n",
    "\n",
    "Pixel positions are not used for later steps,\n",
    "but it is included in the coordinates for instrument view.\n",
    "\n",
    "All pixel positions are relative to the sample position,\n",
    "therefore the sample is at (0, 0, 0).\n",
    "\n",
    "**It might be very slow or not work in the ``VS Code`` jupyter notebook editor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scippneutron as scn\n",
    "\n",
    "da = binned_dg['counts'].sum('t')\n",
    "da.coords[\"position\"] = binned_dg[\"position\"]\n",
    "# Plot one out of 100 pixels to reduce size of docs output\n",
    "view = scn.instrument_view(da[\"id\", ::100], pixel_size=0.0075)\n",
    "view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmx-dev-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
